# Introduction

The following project assesses and evaluates model performance for xG prediction based on 4 models run across logisitic regression, random froest classification, and XGboost classification. The model was trained on 2015/16 top 5 European League event data provided by Statsbomb.

# Setup

### Data Collection

The project combines event data across the top 5 European League (taken from statsbomb) with player valuations and minutes played (taken from transfermarkt) during the 2015/16 season. In an ideal context we would also include tracking data alongside the event data, however this is not available in open formats for the 2015/16 season. Links to the data sources can be found at the bottom of this ReadMe.

### Data Preparation + Feature Engineering

The event data taken from statsbomb was imported through the statsbomb API and was subsequently cleaned and prepped for model use. This included all shots being grouped and separated into headers and non-headers. This was done to provide a basic segregation between two key finish types within a footballing context with different models being applied accordingly to better represent the differences between headers and non-headers. Feature engineering was also extended to the independent variables used to predict expected goals. This included the extraction/creation/grouping of the following variables:
- Angle from shot to goal 
- Distance from shot to goal 
- Inverse Angle 
- Inverse Distance 
- Shot technique 
- First time finishes 
- Assist type 
- Pattern of play 
- Shots under pressure 
- Shots deflected

In addition to the preparation of event data for modelling purposes, player valuation and minutes played data were included for player evaluation and normalisation purposes. Both player valuation and minutes played data were matched via player name to the statsbomb event data using a combination of the fuzzylogic library and manual mapping.

# Modelling

### Metric Selections for the Model:

The idea behind the use of 4 differing model was to separate shooting actions and the factors that affect goal conversion into four categories. These categories are:
- Basic (Incl - Angle, Distance, Inverse angle, Inverse distance, League)
- Singular Player Effects (Incl - Basic + Shot Technique, First time shot)
- Teammate Effects (Incl - Player Effects + Assist type, Pattern of play)
- Opposition Effects (Incl - Teammate + Under pressure, Shot deflected)

These categories seek to provide the differing effects generated by internal and external factors on the shots on the goal and apply them to the model accordingly.

### Model Selection and Development

As xG is the calculation of the probability of a binary outcome (a goal being scored or not), logistical regression, random forest classification, and xGboost classification were used to predict the xG of all shots within the event dataset. These models were initially run without tuning to determine which model naturally fit both headers and non-headers. Evaluations of these models were generated through cross-validated AUC, Brier, and RMSE scores as well as error and log loss plots.

After evaluation, the teammate effect random forest model was used to predict xG for headers and the opposition effect xGboost was used to predict xG for non-headers. Both of the models were tuned and regularised for optimisation and overfitting purposes. They produced the following evaluation scores:

**Figure 1 - Model Scores**

![Model Scores](https://github.com/user-attachments/assets/6eadc41a-3e4c-4aaa-b374-5099e46c4473)

### Feature Importance

Visualisation to come

### Model Evaluation

After predicting xG through the header and non-header models I ran a cross-comparison between my predicted xG and the statsbomb xG (SB at figure 1). This comparison was run using Mean Absolute Error and Root Means Squared Error. As expected, the statsbomb xG produced closer results to that of actual goals scored (see figure 1). As a result scouting prospects were initially evaluated via statsbomb xG data and via my model to ensure there was consistency with the players highlighted as the highest performing. Both the statsbomb model and my model returned the same player recommendations. Thus, my model has been used in the results below.

